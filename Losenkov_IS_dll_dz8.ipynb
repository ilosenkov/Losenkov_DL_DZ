{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9a521631-1f39-4792-ae24-8d0ee001fa5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import open\n",
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e5223491-fd45-43d4-95e5-70cbefb27287",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f35c984-a094-4c41-970e-0cce891be3d7",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 1. Загрузка и преобразование данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6488aa3b-8f97-4724-ae3f-f8f91e94ba8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Класс для создания словаря\n",
    "SOS_token = 0\n",
    "EOS_token = 1\n",
    "\n",
    "class Lang:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n",
    "        self.n_words = 2  # Count SOS and EOS\n",
    "\n",
    "    def addSentence(self, sentence):\n",
    "        for word in sentence.split(' '):\n",
    "            self.addWord(word)\n",
    "\n",
    "    def addWord(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "504593ce-ae60-4b8f-a816-fcc8a535f709",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Изменение кодировка текста на ASCII\n",
    "def unicodeToAscii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn')\n",
    "\n",
    "# Приведение к нижнему регистру, удаление лишних символов\n",
    "def normalizeString(s):\n",
    "    s = unicodeToAscii(s.lower().strip())\n",
    "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
    "    s = re.sub(r\"[^а-яА-Вa-zA-Z.!?]+\", r\" \", s)\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "99a35486-9cdb-4d89-8837-376fb2f68d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Чтение файла. Создание пар фраз\n",
    "def readLangs(lang1, lang2, reverse = False):\n",
    "    \n",
    "    # Read the file and split into lines\n",
    "    lines = open('D:/НЕТОЛОГИЯ/Deep ML/файлы/%s-%s.txt' % (lang1, lang2), encoding='utf-8').\\\n",
    "        read().strip().split('\\n')\n",
    "\n",
    "    # Split every line into pairs and normalize\n",
    "    pairs = [[normalizeString(s) for s in l.split('\\t')[0:2]] for l in lines]\n",
    "\n",
    "    # Reverse pairs, make Lang instances\n",
    "    if reverse:\n",
    "        pairs = [list(reversed(p)) for p in pairs]\n",
    "        input_lang = Lang(lang2)\n",
    "        output_lang = Lang(lang1)\n",
    "    else:\n",
    "        input_lang = Lang(lang1)\n",
    "        output_lang = Lang(lang2)\n",
    "\n",
    "    return input_lang, output_lang, pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a3224c5d-727e-4b6c-b28d-ad32374dfb01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Отбор предложений длиной 30\n",
    "MAX_LENGTH = 30\n",
    "\n",
    "def filterPair(p):\n",
    "    return len(p[0]) < MAX_LENGTH and len(p[1]) < MAX_LENGTH \n",
    "\n",
    "def filterPairs(pairs):\n",
    "    return [pair for pair in pairs if filterPair(pair)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f705e3e7-99f3-4c29-ac2d-5532f04bb608",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read 519900 sentence pairs\n",
      "Trimmed to 519900 sentence pairs\n",
      "Counting words...\n",
      "Counted words:\n",
      "eng 17542\n",
      "rus 60040\n",
      "['is this your purse ?', 'это ваша сумочка ?']\n"
     ]
    }
   ],
   "source": [
    "# Формирование итогового датасета\n",
    "def prepareData(lang1, lang2, reverse=False):\n",
    "    input_lang, output_lang, pairs = readLangs(lang1, lang2)\n",
    "    print(\"Read %s sentence pairs\" % len(pairs))\n",
    "    #pairs = filterPairs(pairs)\n",
    "    print(\"Trimmed to %s sentence pairs\" % len(pairs))\n",
    "    print(\"Counting words...\")\n",
    "    for pair in pairs:\n",
    "        input_lang.addSentence(pair[0])\n",
    "        output_lang.addSentence(pair[1])\n",
    "    print(\"Counted words:\")\n",
    "    print(input_lang.name, input_lang.n_words)\n",
    "    print(output_lang.name, output_lang.n_words)\n",
    "    return input_lang, output_lang, filterPairs(pairs)\n",
    "\n",
    "input_lang, output_lang, pairs = prepareData('eng', 'rus', True)\n",
    "print(random.choice(pairs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b201abc-3e1f-4f03-badb-ec7119a674af",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 2. Функции для обучения и теста"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a4b0fe93-dc3b-43f8-85e1-7f97d6d5979a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoder\n",
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size, num_layers = num_layers)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        output = embedded\n",
    "        output, hidden = self.gru(output) # правка для 2-х слойной GRU\n",
    "        output, hidden = self.gru(output, hidden) \n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2c47253a-e243-48e5-b795-03260d795a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decoder\n",
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, num_layers):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size, num_layers = num_layers)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        output = self.embedding(input).view(1, 1, -1)\n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.gru(output) # правка для 2-х слойной GRU\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        output = self.softmax(self.out(output[0]))\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4007c832-a978-47ea-9333-f0bb14a2d287",
   "metadata": {},
   "outputs": [],
   "source": [
    "def indexesFromSentence(lang, sentence):\n",
    "    return [lang.word2index[word] for word in sentence.split(' ')]\n",
    "\n",
    "def tensorFromSentence(lang, sentence):\n",
    "    indexes = indexesFromSentence(lang, sentence)\n",
    "    indexes.append(EOS_token)\n",
    "    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\n",
    "\n",
    "def tensorsFromPair(pair):\n",
    "    input_tensor = tensorFromSentence(input_lang, pair[0])\n",
    "    target_tensor = tensorFromSentence(output_lang, pair[1])\n",
    "    return (input_tensor, target_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3229344e-0075-4b37-8f09-0dad2c0c25e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Обучение\n",
    "teacher_forcing_ratio = 0.5\n",
    "\n",
    "def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length = 30):\n",
    "    encoder_hidden = encoder.initHidden()\n",
    "\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "\n",
    "    input_length = input_tensor.size(0)\n",
    "    target_length = target_tensor.size(0)\n",
    "\n",
    "    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device = device)\n",
    "\n",
    "    loss = 0\n",
    "\n",
    "    for ei in range(input_length):\n",
    "        encoder_output, encoder_hidden = encoder(\n",
    "            input_tensor[ei], encoder_hidden)\n",
    "        encoder_outputs[ei] = encoder_output[0, 0]\n",
    "\n",
    "    decoder_input = torch.tensor([[SOS_token]], device=device)\n",
    "\n",
    "    decoder_hidden = encoder_hidden\n",
    "\n",
    "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
    "\n",
    "    if use_teacher_forcing:\n",
    "        # Teacher forcing: Feed the target as the next input\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden = decoder(\n",
    "                decoder_input, decoder_hidden)\n",
    "            loss += criterion(decoder_output, target_tensor[di])\n",
    "            decoder_input = target_tensor[di]  # Teacher forcing\n",
    "\n",
    "    else:\n",
    "        # Without teacher forcing: use its own predictions as the next input\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden = decoder(\n",
    "                decoder_input, decoder_hidden)\n",
    "            topv, topi = decoder_output.topk(1)\n",
    "            decoder_input = topi.squeeze().detach()  # detach from history as input\n",
    "\n",
    "            loss += criterion(decoder_output, target_tensor[di])\n",
    "            if decoder_input.item() == EOS_token:\n",
    "                break\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return loss.item() / target_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "935f82f2-c601-4268-a0e0-3e5e96ab6aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "89cdde32-1b92-47f0-9ba9-5bcdabb2b34a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainIters(encoder, decoder, n_iters, print_every = 1000, plot_every = 100, learning_rate = 0.01):\n",
    "    start = time.time()\n",
    "    plot_losses = []\n",
    "    print_loss_total = 0  # Reset every print_every\n",
    "    plot_loss_total = 0  # Reset every plot_every\n",
    "\n",
    "    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
    "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
    "\n",
    "    \n",
    "    training_pairs = [tensorsFromPair(random.choice(pairs))\n",
    "                      for i in range(n_iters)]\n",
    "    \n",
    "    criterion = nn.NLLLoss()\n",
    "        \n",
    "    for iter in tqdm(range(1, n_iters + 1)):\n",
    "        training_pair = training_pairs[iter - 1]\n",
    "        input_tensor = training_pair[0]\n",
    "        target_tensor = training_pair[1]\n",
    "        loss = train(input_tensor, target_tensor, encoder,\n",
    "                     decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
    "        print_loss_total += loss\n",
    "        plot_loss_total += loss\n",
    "\n",
    "        if iter % print_every == 0:\n",
    "            print_loss_avg = print_loss_total / print_every\n",
    "            print_loss_total = 0\n",
    "            print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\n",
    "                                         iter, iter / n_iters * 100, print_loss_avg))\n",
    "\n",
    "        if iter % plot_every == 0:\n",
    "            plot_loss_avg = plot_loss_total / plot_every\n",
    "            plot_losses.append(plot_loss_avg)\n",
    "            plot_loss_total = 0\n",
    "\n",
    "    showPlot(plot_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fc381fd7-408c-46d3-ac3b-49686f1859bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция для визуализации лосса\n",
    "import matplotlib.pyplot as plt\n",
    "plt.switch_backend('agg')\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "\n",
    "def showPlot(points):\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots()\n",
    "    # this locator puts ticks at regular intervals\n",
    "    loc = ticker.MultipleLocator(base=0.2)\n",
    "    ax.yaxis.set_major_locator(loc)\n",
    "    plt.plot(points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8c3d3016-c7a6-4d28-bb7e-3872e9f80fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Тест\n",
    "def evaluate(encoder, decoder, sentence, max_length = MAX_LENGTH):\n",
    "    with torch.no_grad():\n",
    "        input_tensor = tensorFromSentence(input_lang, sentence)\n",
    "        input_length = input_tensor.size()[0]\n",
    "        encoder_hidden = encoder.initHidden()\n",
    "\n",
    "        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "\n",
    "        for ei in range(input_length):\n",
    "            encoder_output, encoder_hidden = encoder(input_tensor[ei],\n",
    "                                                     encoder_hidden)\n",
    "            encoder_outputs[ei] += encoder_output[0, 0]\n",
    "\n",
    "        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\n",
    "\n",
    "        decoder_hidden = encoder_hidden\n",
    "\n",
    "        decoded_words = []\n",
    "\n",
    "        for di in range(max_length):\n",
    "            decoder_output, decoder_hidden = decoder(\n",
    "                decoder_input, decoder_hidden)\n",
    "            topv, topi = decoder_output.data.topk(1)\n",
    "            if topi.item() == EOS_token:\n",
    "                decoded_words.append('<EOS>')\n",
    "                break\n",
    "            else:\n",
    "                decoded_words.append(output_lang.index2word[topi.item()])\n",
    "\n",
    "            decoder_input = topi.squeeze().detach()\n",
    "\n",
    "        return decoded_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "84a2525f-4286-4254-a9c3-4ef3a2758de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция для грубой оценки точности\n",
    "def evaluateRandomly(encoder, decoder, n=10):\n",
    "    acc = 0\n",
    "    for i in range(n):\n",
    "        pair = random.choice(pairs)\n",
    "        print('>', pair[0])\n",
    "        print('=', pair[1])\n",
    "        output_words = evaluate(encoder, decoder, pair[0])\n",
    "        output_sentence = ' '.join(output_words)\n",
    "        print('<', output_sentence)\n",
    "        if output_words == pair[1]:\n",
    "            acc += 1\n",
    "            print('полное совпадение')\n",
    "        print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eb2e301-6313-4f20-89e2-9b4ca0010a7c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 3. GRU с 1 слоем"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "0b0daed7-c8f1-4c3e-8c0d-0a797c1283bd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "hidden_size = 256\n",
    "encoder1 = EncoderRNN(input_lang.n_words, hidden_size, num_layers = 1).to(device)\n",
    "decoder1 = DecoderRNN(hidden_size, output_lang.n_words, num_layers = 1).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "5991cc06-da15-4df5-8cec-b28948c24b03",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 5006/50000 [01:39<14:58, 50.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1m 46s (- 15m 55s) (5000 10%) 2.4141\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 10006/50000 [03:19<14:00, 47.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3m 25s (- 13m 42s) (10000 20%) 2.3924\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 15009/50000 [04:58<11:40, 49.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5m 5s (- 11m 52s) (15000 30%) 2.3592\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 20005/50000 [06:38<10:23, 48.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6m 45s (- 10m 7s) (20000 40%) 2.3574\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 25007/50000 [08:19<08:20, 49.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8m 25s (- 8m 25s) (25000 50%) 2.3350\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 30008/50000 [09:59<06:25, 51.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10m 6s (- 6m 44s) (30000 60%) 2.2958\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 35009/50000 [11:39<04:51, 51.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11m 45s (- 5m 2s) (35000 70%) 2.2839\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 40007/50000 [13:19<03:06, 53.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13m 26s (- 3m 21s) (40000 80%) 2.2666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 45006/50000 [15:01<01:41, 49.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15m 7s (- 1m 40s) (45000 90%) 2.2054\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50000/50000 [16:41<00:00, 49.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16m 47s (- 0m 0s) (50000 100%) 2.2149\n"
     ]
    }
   ],
   "source": [
    "# Обучение\n",
    "trainIters(encoder1, decoder1, n_iters = 50000, print_every = 5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "1b135daa-ec1a-43d7-8fb3-80de8feee96c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> you need to get started .\n",
      "= вам надо начинать .\n",
      "< тебе надо к . <EOS>\n",
      "\n",
      "> this isn t paper .\n",
      "= это не бумага .\n",
      "< это не . . <EOS>\n",
      "\n",
      "> i wish that wasn t the case .\n",
      "= лучше б оно было не так .\n",
      "< на было бы и не . <EOS>\n",
      "\n",
      "> tom is crying in his room .\n",
      "= том плачет в своеи комнате .\n",
      "< том в в в в комнате . <EOS>\n",
      "\n",
      "> you ve lost your mind .\n",
      "= вы с ума сошли .\n",
      "< ты потерял свое . <EOS>\n",
      "\n",
      "> was tom ever married ?\n",
      "= том когда нибудь был женат ?\n",
      "< том когда нибудь женат ? <EOS>\n",
      "\n",
      "> you re being hunted .\n",
      "= на вас охотятся .\n",
      "< ты не . <EOS>\n",
      "\n",
      "> you re not very good .\n",
      "= ты не слишком хорош .\n",
      "< ты не очень хорошо . <EOS>\n",
      "\n",
      "> take this brochure .\n",
      "= возьми эту брошюру .\n",
      "< возьмите эту . <EOS>\n",
      "\n",
      "> i ll come home at ten .\n",
      "= я приду домои в десять .\n",
      "< я вернусь в в . . <EOS>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Оценка качества\n",
    "evaluateRandomly(encoder1, decoder1, n = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e43df5c6-8b0c-4aa1-9716-9ca49e7f2c98",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 4. GRU с 2 слоями"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6d21c04c-1961-4661-87fa-8544aff10f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_size = 256\n",
    "encoder2 = EncoderRNN(input_lang.n_words, hidden_size, num_layers = 2).to(device)\n",
    "decoder2 = DecoderRNN(hidden_size, output_lang.n_words, num_layers = 2).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "961968d6-0cae-4459-9c75-e1419834a2c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 5008/50000 [01:37<15:57, 46.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1m 44s (- 15m 42s) (5000 10%) 4.9985\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 10009/50000 [03:18<13:12, 50.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3m 25s (- 13m 40s) (10000 20%) 4.8544\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 15006/50000 [04:58<11:38, 50.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5m 5s (- 11m 53s) (15000 30%) 4.8120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 20005/50000 [06:39<10:02, 49.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6m 46s (- 10m 10s) (20000 40%) 4.7132\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 25009/50000 [08:20<08:16, 50.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8m 27s (- 8m 27s) (25000 50%) 4.7213\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 30009/50000 [10:01<06:36, 50.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10m 8s (- 6m 45s) (30000 60%) 4.6603\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 35007/50000 [11:40<04:52, 51.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11m 48s (- 5m 3s) (35000 70%) 4.6481\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 40005/50000 [13:20<03:19, 50.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13m 27s (- 3m 21s) (40000 80%) 4.6866\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 45009/50000 [14:59<01:35, 52.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15m 7s (- 1m 40s) (45000 90%) 4.6272\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50000/50000 [16:39<00:00, 50.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16m 46s (- 0m 0s) (50000 100%) 4.6218\n"
     ]
    }
   ],
   "source": [
    "# Обучение\n",
    "trainIters(encoder2, decoder2, n_iters = 50000, print_every = 5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "df77adff-fa02-4b5b-b7c5-eeef818515fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> i think tom will like you .\n",
      "= думаю ты понравишься тому .\n",
      "< я не <EOS>\n",
      "\n",
      "> tom was killed on monday .\n",
      "= тома убили в понедельник .\n",
      "< я не <EOS>\n",
      "\n",
      "> that isn t the same .\n",
      "= это не то же самое .\n",
      "< я не <EOS>\n",
      "\n",
      "> i won t forget .\n",
      "= не забуду .\n",
      "< я не <EOS>\n",
      "\n",
      "> i wanted to die .\n",
      "= я хотел умереть .\n",
      "< я не <EOS>\n",
      "\n",
      "> the movie ran for two hours .\n",
      "= фильм шел два часа .\n",
      "< я не <EOS>\n",
      "\n",
      "> is it hard to milk a goat ?\n",
      "= трудно ли доить козу ?\n",
      "< я не <EOS>\n",
      "\n",
      "> guess whose house it is .\n",
      "= угадаи чеи это дом .\n",
      "< я не <EOS>\n",
      "\n",
      "> it s poison .\n",
      "= это яд .\n",
      "< я не <EOS>\n",
      "\n",
      "> what is this thing for ?\n",
      "= зачем нужна эта вещь ?\n",
      "< я не <EOS>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Оценка качества\n",
    "evaluateRandomly(encoder2, decoder2, n = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71dfae6d-2157-4628-bb34-53b0f97b9a4a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 5. LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "050b503a-1a54-4eb6-8303-d59b3f82f93f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoder для LSTM\n",
    "class EncoderLSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(EncoderLSTM, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.lstm = nn.LSTM(hidden_size, hidden_size)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        output = embedded\n",
    "        output, hidden = self.lstm(output)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device = device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "992400c7-785e-45ce-b98c-a41a86a93824",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decoder для LSTM\n",
    "class DecoderLSTM(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size):\n",
    "        super(DecoderLSTM, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        self.lstm = nn.LSTM(hidden_size, hidden_size)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        output = self.embedding(input).view(1, 1, -1)\n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.lstm(output)\n",
    "        output = self.softmax(self.out(output[0]))\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "642f0eab-e3cd-4a6d-a3b0-71b326857538",
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_size = 256\n",
    "encoder3 = EncoderLSTM(input_lang.n_words, hidden_size).to(device)\n",
    "decoder3 = DecoderLSTM(hidden_size, output_lang.n_words).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2b9154ec-877a-4172-9b35-f88a87db5ca6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 5011/50000 [01:20<13:00, 57.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1m 27s (- 13m 5s) (5000 10%) 5.2503\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 10010/50000 [02:44<10:57, 60.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2m 50s (- 11m 23s) (10000 20%) 4.8690\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 15008/50000 [04:11<09:22, 62.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4m 18s (- 10m 3s) (15000 30%) 4.8126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 20009/50000 [05:37<08:47, 56.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5m 44s (- 8m 36s) (20000 40%) 4.7352\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 25006/50000 [07:03<07:05, 58.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7m 10s (- 7m 10s) (25000 50%) 4.6817\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 30007/50000 [08:26<05:14, 63.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8m 33s (- 5m 42s) (30000 60%) 4.6826\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 35008/50000 [09:49<04:09, 60.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9m 56s (- 4m 15s) (35000 70%) 4.6613\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 40012/50000 [11:14<02:43, 60.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11m 20s (- 2m 50s) (40000 80%) 4.6579\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 45009/50000 [12:38<01:35, 52.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12m 45s (- 1m 25s) (45000 90%) 4.6413\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50000/50000 [14:05<00:00, 59.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14m 12s (- 0m 0s) (50000 100%) 4.6300\n"
     ]
    }
   ],
   "source": [
    "# Обучение\n",
    "trainIters(encoder3, decoder3, n_iters = 50000, print_every = 5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "01ea3738-3ed3-44fb-9c4c-429a9c4a3b27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> you re a big liar .\n",
      "= ты большои лгун .\n",
      "< я не . <EOS>\n",
      "\n",
      "> are you still in college ?\n",
      "= ты еще в колледже ?\n",
      "< я не . <EOS>\n",
      "\n",
      "> i m really old .\n",
      "= я очень старая .\n",
      "< я не . <EOS>\n",
      "\n",
      "> you don t need to do that .\n",
      "= тебе незачем это делать .\n",
      "< я не . <EOS>\n",
      "\n",
      "> tom likes ponies .\n",
      "= том любит пони .\n",
      "< я не . <EOS>\n",
      "\n",
      "> nobody told us either .\n",
      "= нам тоже никто не сказал .\n",
      "< я не . <EOS>\n",
      "\n",
      "> there weren t any survivors .\n",
      "= никто не выжил .\n",
      "< я не . <EOS>\n",
      "\n",
      "> judge for yourself .\n",
      "= сам посуди .\n",
      "< я не . <EOS>\n",
      "\n",
      "> that s mine . give it back .\n",
      "= это мое . отдаи .\n",
      "< я не . <EOS>\n",
      "\n",
      "> we re very happy .\n",
      "= мы очень счастливы .\n",
      "< я не . <EOS>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Оценка качества\n",
    "evaluateRandomly(encoder3, decoder3, n = 10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
