{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b1a85b65-f04d-46c7-8f36-36c4d2c4172c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import time\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e71ea9ed-6022-4f47-a633-389a7a3a416e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b1554a1-dbd4-41d9-8fb2-e170f593a1dc",
   "metadata": {},
   "source": [
    "### Задание 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44fb98c5-124f-41c1-bae0-94976436d1ce",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### 1. Генерация данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e7e966ac-9866-407e-a37b-d337635e8d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция для генерации новой числовой последовательности\n",
    "def generate_seq(number):\n",
    "    number = number\n",
    "    new_number = ''\n",
    "    for i, d in enumerate(number):\n",
    "        if i == 0:\n",
    "            new_number += d\n",
    "        else:\n",
    "           new_d = int(d) + int(number[i-1])\n",
    "           if new_d >= 10:\n",
    "                new_d -= 10\n",
    "                new_number += str(new_d)\n",
    "           else:\n",
    "               new_number += str(new_d)\n",
    "    return new_number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9ee41f39-5f58-4247-b283-1fe570548769",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200000/200000 [00:09<00:00, 21917.62it/s]\n"
     ]
    }
   ],
   "source": [
    "# Датасет для обучения из 200 тыс последовательностей длинной 50 символов. X - исходное число, Y - новое число\n",
    "X = []\n",
    "for i in tqdm(range(2*10**5)):\n",
    "    number = ''\n",
    "    while True:\n",
    "        number += str(random.randint(0,9))\n",
    "        if len(number) == 50:\n",
    "            X.append(number)\n",
    "            break\n",
    "\n",
    "Y = [(generate_seq(i)) for i in X]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cf7e6583-ede7-450b-b6b5-dbe0cc3b8f8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200000 200000\n",
      "50 50\n"
     ]
    }
   ],
   "source": [
    "# Разбиваем последовательности на символы\n",
    "X = [[c for c in seq] for seq in X]\n",
    "Y = [[c for c in seq] for seq in Y]\n",
    "\n",
    "print(len(X), len(Y))\n",
    "print(len(X[0]), len(Y[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "34ce4216-b226-4c69-979d-7284d57e5c35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0': 0,\n",
       " '1': 1,\n",
       " '2': 2,\n",
       " '3': 3,\n",
       " '4': 4,\n",
       " '5': 5,\n",
       " '6': 6,\n",
       " '7': 7,\n",
       " '8': 8,\n",
       " '9': 9}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Словарь для символов\n",
    "CHAR_TO_INDEX = {str(c): i for i, c in enumerate(range(0, 10))}\n",
    "CHAR_TO_INDEX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c865c1b1-0d7a-43fb-8ef4-fa87a9e954ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200000/200000 [01:19<00:00, 2516.04it/s]\n",
      "100%|██████████| 200000/200000 [01:19<00:00, 2528.11it/s]\n"
     ]
    }
   ],
   "source": [
    "# Кодирование символов\n",
    "max_len = 50 # длинна последовательности\n",
    "\n",
    "X_vec = torch.zeros((len(X), max_len), dtype = torch.int64)\n",
    "for i in tqdm(range(len(X))):\n",
    "    for j, w in enumerate(X[i]):\n",
    "        X_vec[i, j] = CHAR_TO_INDEX.get(w)\n",
    "\n",
    "Y_vec = torch.zeros((len(Y), max_len), dtype = torch.int64)\n",
    "for i in  tqdm(range(len(Y))):\n",
    "    for j, w in enumerate(Y[i]):\n",
    "        Y_vec[i, j] = CHAR_TO_INDEX.get(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ad12ae74-8bb9-4eac-942c-98a250ec478f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([200000, 50]) torch.Size([200000, 50])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([7, 8, 9, 9, 3, 0, 7, 4, 5, 2, 6, 3, 6, 2, 7, 5, 7, 8, 0, 6, 8, 1, 5, 2,\n",
       "         5, 7, 5, 6, 3, 0, 0, 5, 6, 2, 6, 2, 5, 0, 5, 7, 2, 9, 9, 4, 8, 9, 7, 8,\n",
       "         8, 3]),\n",
       " tensor([7, 5, 7, 8, 2, 3, 7, 1, 9, 7, 8, 9, 9, 8, 9, 2, 2, 5, 8, 6, 4, 9, 6, 7,\n",
       "         7, 2, 2, 1, 9, 3, 0, 5, 1, 8, 8, 8, 7, 5, 5, 2, 9, 1, 8, 3, 2, 7, 6, 5,\n",
       "         6, 1]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(X_vec.shape, Y_vec.shape)\n",
    "X_vec[0], Y_vec[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "31c3dcf4-ec94-4ecb-b6c0-f219d49b13ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200000/200000 [01:20<00:00, 2471.94it/s]\n",
      "100%|██████████| 200000/200000 [01:20<00:00, 2481.73it/s]\n"
     ]
    }
   ],
   "source": [
    "# Кодирование символов\n",
    "max_len = 50 # длинна последовательности\n",
    "\n",
    "X_vec2 = torch.zeros((len(X), max_len), dtype = torch.float32)\n",
    "for i in tqdm(range(len(X))):\n",
    "    for j, w in enumerate(X[i]):\n",
    "        X_vec2[i, j] = CHAR_TO_INDEX.get(w)\n",
    "\n",
    "Y_vec2 = torch.zeros((len(Y), max_len), dtype = torch.float32)\n",
    "for i in  tqdm(range(len(Y))):\n",
    "    for j, w in enumerate(Y[i]):\n",
    "        Y_vec2[i, j] = CHAR_TO_INDEX.get(w)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5213895-0f4b-4492-be06-66b7add7e1d2",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### 2. Создание и обучение модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f27d38e7-eecb-4391-a22a-c18cbb82ecf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "loss = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1684730f-0ea0-47c7-9d63-dbc291c91c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция для обучения\n",
    "def model_train(model, num_epochs, optimizer):\n",
    "    for epoch in range(num_epochs):\n",
    "        start = time.time()\n",
    "        train_loss = 0\n",
    "        train_iters = 0\n",
    "        \n",
    "        model.train()\n",
    "        for i in range(int(len(X_vec) / batch_size)):\n",
    "            X_batch = X_vec[i * batch_size:(i + 1) * batch_size]\n",
    "            Y_batch = Y_vec[i * 100:(i + 1) * batch_size].flatten()\n",
    "            \n",
    "            X_batch, Y_batch = X_batch.to(device), Y_batch.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            y_pred = model.forward(X_batch)\n",
    "            y_pred = y_pred.view(-1, len(CHAR_TO_INDEX))\n",
    "            l = loss(y_pred, Y_batch)\n",
    "            l.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss += l.item()\n",
    "            train_iters += 1\n",
    "    \n",
    "        print(f'ep: {epoch}, loss: {train_loss/train_iters:.4f}, time {time.time() - start:.1f} sec')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7443c034-cbe2-4842-969a-68bc449ec487",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "##### 2.1. RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3da8740e-a6fc-4d95-90b2-6d4c6c8e00df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Задаем сеть\n",
    "class RNN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(RNN, self).__init__()\n",
    "        self.embedding = torch.nn.Embedding(len(CHAR_TO_INDEX), 30)\n",
    "        self.rnn = torch.nn.RNN(30, 128)\n",
    "        self.out = torch.nn.Linear(128, len(CHAR_TO_INDEX))\n",
    "\n",
    "    def forward(self, sequence, state=None):\n",
    "        x = self.embedding(sequence)\n",
    "        o, s = self.rnn(x)\n",
    "        x, s = self.rnn(x, s)\n",
    "        return self.out(x)\n",
    "        \n",
    "model_rnn = RNN()\n",
    "model_rnn = model_rnn.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "6039f1e4-d96a-4338-a36e-fcacc015408a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep: 0, loss: 2.3100, time 2.9 sec\n",
      "ep: 1, loss: 2.3097, time 2.5 sec\n",
      "ep: 2, loss: 2.3096, time 2.5 sec\n",
      "ep: 3, loss: 2.3095, time 2.5 sec\n",
      "ep: 4, loss: 2.3094, time 2.5 sec\n",
      "ep: 5, loss: 2.3093, time 2.5 sec\n",
      "ep: 6, loss: 2.3095, time 2.7 sec\n",
      "ep: 7, loss: 2.3093, time 2.5 sec\n",
      "ep: 8, loss: 2.3095, time 2.5 sec\n",
      "ep: 9, loss: 2.3094, time 2.5 sec\n",
      "ep: 10, loss: 2.3094, time 2.6 sec\n",
      "ep: 11, loss: 2.3093, time 2.5 sec\n",
      "ep: 12, loss: 2.3093, time 2.6 sec\n",
      "ep: 13, loss: 2.3092, time 2.6 sec\n",
      "ep: 14, loss: 2.3092, time 2.6 sec\n",
      "ep: 15, loss: 2.3092, time 2.5 sec\n",
      "ep: 16, loss: 2.3093, time 2.5 sec\n",
      "ep: 17, loss: 2.3093, time 2.5 sec\n",
      "ep: 18, loss: 2.3093, time 2.7 sec\n",
      "ep: 19, loss: 2.3092, time 2.6 sec\n"
     ]
    }
   ],
   "source": [
    "# Обучение\n",
    "optim_rnn = torch.optim.Adam(model_rnn.parameters(), lr = 0.01)\n",
    "model_train(model = model_rnn, num_epochs = 20, optimizer = optim_rnn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "665b859e-50e5-429f-8bf4-cdfefa8bf77a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "##### 2.2. LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1488cd4f-b59e-42ce-80c1-f2924f6fc12b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Класс для сети\n",
    "class LSTM(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(len(CHAR_TO_INDEX), 50)\n",
    "        self.hidden = nn.LSTM(input_size = 50, hidden_size = 128, num_layers = 2)\n",
    "        self.out = nn.Linear(128, len(CHAR_TO_INDEX))\n",
    "        \n",
    "    def forward(self, sequence):\n",
    "        x = self.embedding(sequence)\n",
    "        x, s = self.hidden(x)\n",
    "        return self.out(x)\n",
    "\n",
    "model_lstm = LSTM()\n",
    "model_lstm = model_lstm.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "a5331a8e-006e-4cda-bdd4-ced445ea2dca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep: 0, loss: 2.3012, time 10.2 sec\n",
      "ep: 1, loss: 2.3011, time 9.7 sec\n",
      "ep: 2, loss: 2.3010, time 9.8 sec\n",
      "ep: 3, loss: 2.3010, time 9.8 sec\n",
      "ep: 4, loss: 2.3010, time 9.8 sec\n",
      "ep: 5, loss: 2.3010, time 9.9 sec\n",
      "ep: 6, loss: 2.3010, time 9.9 sec\n",
      "ep: 7, loss: 2.3010, time 10.1 sec\n",
      "ep: 8, loss: 2.3010, time 10.1 sec\n",
      "ep: 9, loss: 2.3010, time 10.3 sec\n",
      "ep: 10, loss: 2.3010, time 10.5 sec\n",
      "ep: 11, loss: 2.3010, time 10.7 sec\n",
      "ep: 12, loss: 2.3010, time 10.7 sec\n",
      "ep: 13, loss: 2.3010, time 11.2 sec\n",
      "ep: 14, loss: 2.3010, time 11.1 sec\n",
      "ep: 15, loss: 2.3010, time 11.1 sec\n",
      "ep: 16, loss: 2.3010, time 11.1 sec\n",
      "ep: 17, loss: 2.3010, time 11.4 sec\n",
      "ep: 18, loss: 2.3010, time 11.2 sec\n",
      "ep: 19, loss: 2.3010, time 11.4 sec\n"
     ]
    }
   ],
   "source": [
    "# Обучение\n",
    "optim_lstm = torch.optim.Adam(model_lstm.parameters(), lr = 0.01)\n",
    "model_train(model = model_lstm, num_epochs = 20, optimizer = optim_lstm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c567dae-9d29-42b5-a2d4-9a67d788091b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "##### 2.3. GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "6d39926d-2c95-4bac-a328-d11a2017d33d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Класс для сети\n",
    "class GRU(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(len(CHAR_TO_INDEX), 30)\n",
    "        self.hidden = nn.GRU(input_size = 30, hidden_size = 128, batch_first = True)\n",
    "        self.out = nn.Linear(128, len(CHAR_TO_INDEX))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        x, s = self.hidden(x)\n",
    "        y = self.out(s)\n",
    "        return y\n",
    "\n",
    "model_gru = GRU()\n",
    "model_gru = model_gru.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "d3b8c856-3c80-45c1-9aa5-ddb2fba7b419",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected input batch_size (100) to match target batch_size (5000).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[81], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Обучение\u001b[39;00m\n\u001b[0;32m      2\u001b[0m optim_gru \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdam(model_gru\u001b[38;5;241m.\u001b[39mparameters(), lr \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.01\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m \u001b[43mmodel_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmodel_gru\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43moptim_gru\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[27], line 18\u001b[0m, in \u001b[0;36mmodel_train\u001b[1;34m(model, num_epochs, optimizer)\u001b[0m\n\u001b[0;32m     16\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mforward(X_batch)\n\u001b[0;32m     17\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m y_pred\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mlen\u001b[39m(CHAR_TO_INDEX))\n\u001b[1;32m---> 18\u001b[0m l \u001b[38;5;241m=\u001b[39m \u001b[43mloss\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     19\u001b[0m l\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m     20\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[1;32m~\\.conda\\envs\\gpu\\lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\.conda\\envs\\gpu\\lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32m~\\.conda\\envs\\gpu\\lib\\site-packages\\torch\\nn\\modules\\loss.py:1297\u001b[0m, in \u001b[0;36mCrossEntropyLoss.forward\u001b[1;34m(self, input, target)\u001b[0m\n\u001b[0;32m   1296\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, target: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m-> 1297\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_entropy\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1298\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1299\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1300\u001b[0m \u001b[43m        \u001b[49m\u001b[43mweight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1301\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1302\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreduction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1303\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1304\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\.conda\\envs\\gpu\\lib\\site-packages\\torch\\nn\\functional.py:3494\u001b[0m, in \u001b[0;36mcross_entropy\u001b[1;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[0;32m   3492\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m size_average \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m reduce \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   3493\u001b[0m     reduction \u001b[38;5;241m=\u001b[39m _Reduction\u001b[38;5;241m.\u001b[39mlegacy_get_string(size_average, reduce)\n\u001b[1;32m-> 3494\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_nn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_entropy_loss\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3495\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3496\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3497\u001b[0m \u001b[43m    \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3498\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_Reduction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_enum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3499\u001b[0m \u001b[43m    \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3500\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3501\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mValueError\u001b[0m: Expected input batch_size (100) to match target batch_size (5000)."
     ]
    }
   ],
   "source": [
    "# Обучение. Не получилось обучить модель. Не смог устранить ошибку в несовпадени размерностей батча Y и выхода сети.\n",
    "optim_gru = torch.optim.Adam(model_gru.parameters(), lr = 0.01)\n",
    "model_train(model = model_gru, num_epochs = 20, optimizer = optim_gru)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13373ae9-218e-43ed-bfd9-eb2ad2894321",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### 3. Проверка работы модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "17b9a3de-24d2-453a-b426-a0f64590790d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50000/50000 [00:02<00:00, 22515.08it/s]\n"
     ]
    }
   ],
   "source": [
    "# Данные для проверки\n",
    "test = []\n",
    "for i in tqdm(range(5*10**4)):\n",
    "    number = ''\n",
    "    while True:\n",
    "        number += str(random.randint(0,9))\n",
    "        if len(number) == 50:\n",
    "            test.append(number)\n",
    "            break\n",
    "\n",
    "test_new = [(generate_seq(i)) for i in test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "aecce4bc-afd9-4e0c-9389-538f3b3541ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Словарь, где ключ - исходная последовательность, значение - преобразованная\n",
    "test_dict = dict(zip(test, test_new))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "9d9b7b61-61dc-426d-a9d6-468b87877ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция для предсказаний и расчета точности\n",
    "INDEX_TO_CHAR = [w for w in '0123456789']\n",
    "def model_test(test, model, name):\n",
    "    accuracy = 0\n",
    "    for seq, seq_new in tqdm(test_dict.items()):\n",
    "        seq = list(seq)\n",
    "        seq = [CHAR_TO_INDEX.get(s, 0) for s in seq]\n",
    "        answers = model_rnn.to('cpu').forward(torch.tensor(seq))\n",
    "        probas, indices = answers.topk(1)\n",
    "        pred = ''.join([INDEX_TO_CHAR[ind.item()] for ind in indices.flatten()])\n",
    "        if pred == seq_new: \n",
    "            accuracy += 1\n",
    "        \n",
    "    print(f'Model: {name}, accuracy: {(accuracy/len(test) * 100):.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "b43730ac-a880-4c75-9455-e52cfe8051c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50000/50000 [03:04<00:00, 270.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: RNN, accuracy: 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Тест RNN\n",
    "model_test(test = test_dict, model = model_rnn, name = 'RNN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "76dc5656-2f8f-4147-94ea-cc71c161cb6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50000/50000 [03:03<00:00, 273.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: LSTM, accuracy: 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Тест LSTM\n",
    "model_test(test = test_dict, model = model_lstm, name = 'LSTM')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63e2b675-8c62-4824-b40e-719a26ee7b8e",
   "metadata": {},
   "source": [
    "### Задание 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69fcc181-7325-4137-aae1-3328cc9b5209",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### 1. Загрузка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2ae629ca-5bfd-450c-8a91-1cfe25d06dac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length: 600893\n"
     ]
    }
   ],
   "source": [
    "# Загрузка файла, удаление пробелов, оставление только буквенных символов\n",
    "import re\n",
    "with open(r\"D:\\НЕТОЛОГИЯ\\Deep ML\\файлы\\nietzsche.txt\", encoding = 'utf-8') as f:\n",
    "    text = f.read().lower()\n",
    "print('length:', len(text))\n",
    "text = re.sub('[^a-z ]', ' ', text)\n",
    "text = re.sub('\\s+', ' ', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c997b2af-5a35-4024-b3bd-c9c4e1a6a5aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Словарь для символов\n",
    "INDEX_TO_CHAR2 = sorted(list(set(text)))\n",
    "CHAR_TO_INDEX2 = {c: i for i, c in enumerate(INDEX_TO_CHAR2)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f7b757c0-83e4-42c6-b953-d5b98abe1de1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num sents: 193075\n"
     ]
    }
   ],
   "source": [
    "# Разделение строк\n",
    "max_len2 = 40\n",
    "step = 3\n",
    "SENTENCES = []\n",
    "NEXT_CHARS = []\n",
    "for i in range(0, len(text) - max_len2, step):\n",
    "    SENTENCES.append(text[i: i + max_len2])\n",
    "    NEXT_CHARS.append(text[i + max_len2])\n",
    "print('Num sents:', len(SENTENCES))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e1bd519f-a2cb-4bc1-83ed-6f667264d3e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "193075it [01:01, 3155.28it/s]\n"
     ]
    }
   ],
   "source": [
    "#Векторизация\n",
    "X_text = torch.zeros((len(SENTENCES), max_len2), dtype=int)\n",
    "Y_text = torch.zeros((len(SENTENCES)), dtype=int)\n",
    "\n",
    "for i, sentence in tqdm(enumerate(SENTENCES)):\n",
    "    for t, char in enumerate(sentence):\n",
    "        X_text[i, t] = CHAR_TO_INDEX2[char]\n",
    "    Y_text[i] = CHAR_TO_INDEX2[NEXT_CHARS[i]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff98863e-a381-4497-b889-6b85a9fb3c94",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### 2. Обучение LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ed80efd6-e933-4a2c-b371-848f6c380170",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size2 = 512\n",
    "dataset = torch.utils.data.TensorDataset(X_text, Y_text)\n",
    "data = torch.utils.data.DataLoader(dataset, batch_size2, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "df5e8cb4-a661-45b7-9b7c-42ecb716ce88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Класс для сети\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self, rnnClass, dictionary_size, embedding_size, num_hiddens, num_classes):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.num_hiddens = num_hiddens\n",
    "        self.embedding = nn.Embedding(dictionary_size, embedding_size)\n",
    "        self.hidden = rnnClass(embedding_size, num_hiddens, batch_first=True)\n",
    "        self.output = nn.Linear(num_hiddens, num_classes)\n",
    "        \n",
    "    def forward(self, X):\n",
    "        out = self.embedding(X)\n",
    "        _, state = self.hidden(out)\n",
    "        predictions = self.output(state[0].squeeze())\n",
    "        return predictions\n",
    "\n",
    "model_lstm2 = NeuralNetwork(nn.LSTM, len(CHAR_TO_INDEX2), 64, 128, len(CHAR_TO_INDEX2))\n",
    "model_lstm2 = model_lstm2.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "b42de7c5-b383-41cb-bc8c-11d0fdff2b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(preds):\n",
    "    softmaxed = torch.softmax(preds, 0)\n",
    "    probas = torch.distributions.multinomial.Multinomial(1, softmaxed).sample()\n",
    "    return probas.argmax()\n",
    "\n",
    "def generate_text():\n",
    "    start_index = random.randint(0, len(text) - max_len2 - 1)\n",
    "\n",
    "    generated = ''\n",
    "    sentence = text[start_index: start_index + max_len2]\n",
    "    generated += sentence\n",
    "\n",
    "    for i in range(max_len2):\n",
    "        x_pred = torch.zeros((1, max_len2), dtype=int)\n",
    "        for t, char in enumerate(generated[-max_len2:]):\n",
    "            x_pred[0, t] = CHAR_TO_INDEX2[char]\n",
    "        \n",
    "        preds = model_lstm2(x_pred.to(device)).cpu()\n",
    "        next_char = INDEX_TO_CHAR2[sample(preds)]\n",
    "        generated = generated + next_char\n",
    "\n",
    "    print(generated[:max_len2] + ' |' + generated[max_len2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "00ee8a8f-bf65-4a44-938f-eed5aaf63076",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep: 0, loss: 1.3420, time 3.9 sec\n",
      "vilizations there are also attempts at t |he ways of spirts calselies have even ha\n",
      "ep: 1, loss: 1.3477, time 3.5 sec\n",
      "eternal too late in every sense may perh |aps fant ase cascmers him indistraint al\n",
      "ep: 2, loss: 1.3432, time 3.7 sec\n",
      "homines religiosi among the artists as t |he incertainty and frictes hime perispec\n",
      "ep: 3, loss: 1.3516, time 3.5 sec\n",
      "the more and its responsibility and who  |however in the termst be condioned non a\n",
      "ep: 4, loss: 1.3661, time 3.6 sec\n",
      "ay be loved or whatever things conduce t |o ademals oftening and spretuing to the \n",
      "ep: 5, loss: 1.3714, time 3.5 sec\n",
      "ee nature falsely that is to say stoical | this looked to recouse whethic that lov\n",
      "ep: 6, loss: 1.3692, time 3.6 sec\n",
      "ng as mankind has existed there have als |o being reserves to profound him equatio\n",
      "ep: 7, loss: 1.3532, time 3.6 sec\n",
      "de with the conception morality in that  |has evil even emrectivency asserter conc\n",
      "ep: 8, loss: 1.3473, time 3.6 sec\n",
      "r will to live their nerves they employ  |to be fell cause called to seems for any\n",
      "ep: 9, loss: 1.3676, time 3.5 sec\n",
      "them commendation for a defect as the op |en the hardantable to that strongew the \n",
      "ep: 10, loss: 1.3597, time 3.6 sec\n",
      "to the ambitions which prompt one to hav |e then who manifews at the low be a goin\n",
      "ep: 11, loss: 1.3815, time 3.6 sec\n",
      "and perpendicular stability are lacking  |had new necessary too lown this chren bu\n",
      "ep: 12, loss: 1.3761, time 3.6 sec\n",
      " of wisdom sacrifice for knowledge heroi |sts and deness the wild and leoual innti\n",
      "ep: 13, loss: 1.3811, time 3.5 sec\n",
      "i myself can by no means doubt i see the |se operation has be for us pathing of wa\n",
      "ep: 14, loss: 1.3693, time 3.6 sec\n",
      "rthly muscular violent far too troubleso |n que how one esteed henceful of himilis\n",
      "ep: 15, loss: 1.3971, time 3.5 sec\n",
      "ity has not been lacking in france for t |he extinteler of life whom thus has anol\n",
      "ep: 16, loss: 1.3823, time 3.7 sec\n",
      "to glorify himself and gave superiority  |are decarisomed he still the pothy aswin\n",
      "ep: 17, loss: 1.3675, time 3.5 sec\n",
      " order to spare himself pain does injury | confinter was improduce his severately \n",
      "ep: 18, loss: 1.3938, time 3.6 sec\n",
      "ferred to freedom the comparative classi |ng through profound even dange sense of \n",
      "ep: 19, loss: 1.3800, time 3.5 sec\n",
      "care to reduce men to the level of these | cause his good brose which which as the\n"
     ]
    }
   ],
   "source": [
    "# Обучение модели и генерация текста\n",
    "loss = nn.CrossEntropyLoss()\n",
    "optim_lstm2 = torch.optim.Adam(model_lstm2.parameters(), lr = 0.01)\n",
    "\n",
    "for epoch in range(20):\n",
    "    start = time.time()\n",
    "    train_loss = 0\n",
    "    train_passed = 0\n",
    "\n",
    "    model_lstm2.train()\n",
    "    for X_b, y_b in data:\n",
    "        X_b, y_b = X_b.to(device), y_b.to(device)\n",
    "        optim_lstm2.zero_grad()\n",
    "        answers = model_lstm2(X_b)\n",
    "        l = loss(answers, y_b)\n",
    "        train_loss += l.item()\n",
    "\n",
    "        l.backward()\n",
    "        optim_lstm2.step()\n",
    "        train_passed += 1\n",
    "\n",
    "    print(f'ep: {epoch}, loss: {train_loss/train_passed:.4f}, time {time.time() - start:.1f} sec')\n",
    "    model_lstm2.eval()\n",
    "    generate_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8021cccd-726b-4d3b-8f4e-ab0aaccb788a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "697528e4-a623-4d36-8f26-0b1121c2e059",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
