{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b1a85b65-f04d-46c7-8f36-36c4d2c4172c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import time\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e71ea9ed-6022-4f47-a633-389a7a3a416e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b1554a1-dbd4-41d9-8fb2-e170f593a1dc",
   "metadata": {},
   "source": [
    "### Задание 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44fb98c5-124f-41c1-bae0-94976436d1ce",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### 1. Генерация данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e7e966ac-9866-407e-a37b-d337635e8d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция для генерации новой числовой последовательности\n",
    "def generate_seq(number):\n",
    "    number = number\n",
    "    new_number = ''\n",
    "    for i, d in enumerate(number):\n",
    "        if i == 0:\n",
    "            new_number += d\n",
    "        else:\n",
    "           new_d = int(d) + int(number[i-1])\n",
    "           if new_d >= 10:\n",
    "                new_d -= 10\n",
    "                new_number += str(new_d)\n",
    "           else:\n",
    "               new_number += str(new_d)\n",
    "    return new_number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9ee41f39-5f58-4247-b283-1fe570548769",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200000/200000 [00:09<00:00, 20879.65it/s]\n"
     ]
    }
   ],
   "source": [
    "# Датасет для обучения из 200 тыс последовательностей длинной 50 символов. X - исходное число, Y - новое число\n",
    "X = []\n",
    "for i in tqdm(range(2*10**5)):\n",
    "    number = ''\n",
    "    while True:\n",
    "        number += str(random.randint(0,9))\n",
    "        if len(number) == 50:\n",
    "            X.append(number)\n",
    "            break\n",
    "\n",
    "Y = [(generate_seq(i)) for i in X]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cf7e6583-ede7-450b-b6b5-dbe0cc3b8f8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200000 200000\n",
      "50 50\n"
     ]
    }
   ],
   "source": [
    "# Разбиваем последовательности на символы\n",
    "X = [[c for c in seq] for seq in X]\n",
    "Y = [[c for c in seq] for seq in Y]\n",
    "\n",
    "print(len(X), len(Y))\n",
    "print(len(X[0]), len(Y[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "34ce4216-b226-4c69-979d-7284d57e5c35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0': 0,\n",
       " '1': 1,\n",
       " '2': 2,\n",
       " '3': 3,\n",
       " '4': 4,\n",
       " '5': 5,\n",
       " '6': 6,\n",
       " '7': 7,\n",
       " '8': 8,\n",
       " '9': 9}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Словарь для символов\n",
    "CHAR_TO_INDEX = {str(c): i for i, c in enumerate(range(0, 10))}\n",
    "CHAR_TO_INDEX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c865c1b1-0d7a-43fb-8ef4-fa87a9e954ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200000/200000 [01:24<00:00, 2378.25it/s]\n",
      "100%|██████████| 200000/200000 [01:24<00:00, 2371.95it/s]\n"
     ]
    }
   ],
   "source": [
    "# Кодирование символов\n",
    "max_len = 50 # длинна последовательности\n",
    "\n",
    "X_vec = torch.zeros((len(X), max_len), dtype = torch.int64)\n",
    "for i in tqdm(range(len(X))):\n",
    "    for j, w in enumerate(X[i]):\n",
    "        X_vec[i, j] = CHAR_TO_INDEX.get(w)\n",
    "\n",
    "Y_vec = torch.zeros((len(Y), max_len), dtype = torch.int64)\n",
    "for i in  tqdm(range(len(Y))):\n",
    "    for j, w in enumerate(Y[i]):\n",
    "        Y_vec[i, j] = CHAR_TO_INDEX.get(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ad12ae74-8bb9-4eac-942c-98a250ec478f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([200000, 50]) torch.Size([200000, 50])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([7, 8, 9, 9, 3, 0, 7, 4, 5, 2, 6, 3, 6, 2, 7, 5, 7, 8, 0, 6, 8, 1, 5, 2,\n",
       "         5, 7, 5, 6, 3, 0, 0, 5, 6, 2, 6, 2, 5, 0, 5, 7, 2, 9, 9, 4, 8, 9, 7, 8,\n",
       "         8, 3]),\n",
       " tensor([7, 5, 7, 8, 2, 3, 7, 1, 9, 7, 8, 9, 9, 8, 9, 2, 2, 5, 8, 6, 4, 9, 6, 7,\n",
       "         7, 2, 2, 1, 9, 3, 0, 5, 1, 8, 8, 8, 7, 5, 5, 2, 9, 1, 8, 3, 2, 7, 6, 5,\n",
       "         6, 1]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(X_vec.shape, Y_vec.shape)\n",
    "X_vec[0], Y_vec[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5213895-0f4b-4492-be06-66b7add7e1d2",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### 2. Создание и обучение модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f27d38e7-eecb-4391-a22a-c18cbb82ecf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "loss = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1684730f-0ea0-47c7-9d63-dbc291c91c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция для обучения\n",
    "def model_train(model, num_epochs, optimizer):\n",
    "    for epoch in range(num_epochs):\n",
    "        start = time.time()\n",
    "        train_loss = 0\n",
    "        train_iters = 0\n",
    "        \n",
    "        model.train()\n",
    "        for i in range(int(len(X_vec) / batch_size)):\n",
    "            X_batch = X_vec[i * batch_size:(i + 1) * batch_size]\n",
    "            Y_batch = Y_vec[i * 100:(i + 1) * batch_size].flatten()\n",
    "            \n",
    "            X_batch, Y_batch = X_batch.to(device), Y_batch.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            y_pred = model.forward(X_batch)\n",
    "            y_pred = y_pred.view(-1, len(CHAR_TO_INDEX))\n",
    "            l = loss(y_pred, Y_batch)\n",
    "            l.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss += l.item()\n",
    "            train_iters += 1\n",
    "    \n",
    "        print(f'ep: {epoch}, loss: {train_loss/train_iters:.4f}, time {time.time() - start:.1f} sec')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7443c034-cbe2-4842-969a-68bc449ec487",
   "metadata": {},
   "source": [
    "##### 2.1. RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3da8740e-a6fc-4d95-90b2-6d4c6c8e00df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Задаем сеть\n",
    "class RNN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(RNN, self).__init__()\n",
    "        self.embedding = torch.nn.Embedding(len(CHAR_TO_INDEX), 30)\n",
    "        self.rnn = torch.nn.RNN(30, 128)\n",
    "        self.out = torch.nn.Linear(128, len(CHAR_TO_INDEX))\n",
    "\n",
    "    def forward(self, sequence, state=None):\n",
    "        x = self.embedding(sequence)\n",
    "        o, s = self.rnn(x)\n",
    "        x, s = self.rnn(x, s)\n",
    "        return self.out(x)\n",
    "        \n",
    "model_rnn = RNN()\n",
    "model_rnn = model_rnn.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6039f1e4-d96a-4338-a36e-fcacc015408a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep: 0, loss: 2.3085, time 5.6 sec\n",
      "ep: 1, loss: 2.3093, time 5.2 sec\n",
      "ep: 2, loss: 2.3093, time 5.4 sec\n",
      "ep: 3, loss: 2.3093, time 5.3 sec\n",
      "ep: 4, loss: 2.3093, time 5.3 sec\n",
      "ep: 5, loss: 2.3093, time 5.6 sec\n",
      "ep: 6, loss: 2.3093, time 5.4 sec\n",
      "ep: 7, loss: 2.3093, time 5.2 sec\n",
      "ep: 8, loss: 2.3093, time 5.3 sec\n",
      "ep: 9, loss: 2.3093, time 5.4 sec\n",
      "ep: 10, loss: 2.3093, time 5.2 sec\n",
      "ep: 11, loss: 2.3093, time 5.2 sec\n",
      "ep: 12, loss: 2.3093, time 5.2 sec\n",
      "ep: 13, loss: 2.3093, time 5.3 sec\n",
      "ep: 14, loss: 2.3093, time 5.3 sec\n",
      "ep: 15, loss: 2.3093, time 5.3 sec\n",
      "ep: 16, loss: 2.3093, time 5.2 sec\n",
      "ep: 17, loss: 2.3093, time 5.4 sec\n",
      "ep: 18, loss: 2.3093, time 5.2 sec\n",
      "ep: 19, loss: 2.3093, time 5.2 sec\n"
     ]
    }
   ],
   "source": [
    "# Обучение\n",
    "optim_rnn = torch.optim.Adam(model_rnn.parameters(), lr = 0.01)\n",
    "model_train(model = model_rnn, num_epochs = 20, optimizer = optim_rnn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "665b859e-50e5-429f-8bf4-cdfefa8bf77a",
   "metadata": {},
   "source": [
    "##### 2.2. LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1488cd4f-b59e-42ce-80c1-f2924f6fc12b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Класс для сети\n",
    "class LSTM(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(len(CHAR_TO_INDEX), 50)\n",
    "        self.hidden = nn.LSTM(input_size = 50, hidden_size = 128, num_layers = 2)\n",
    "        self.out = nn.Linear(128, len(CHAR_TO_INDEX))\n",
    "        \n",
    "    def forward(self, sequence):\n",
    "        x = self.embedding(sequence)\n",
    "        x, s = self.hidden(x)\n",
    "        return self.out(x)\n",
    "\n",
    "model_lstm = LSTM()\n",
    "model_lstm = model_lstm.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a5331a8e-006e-4cda-bdd4-ced445ea2dca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep: 0, loss: 2.3013, time 10.0 sec\n",
      "ep: 1, loss: 2.3011, time 10.0 sec\n",
      "ep: 2, loss: 2.3011, time 10.4 sec\n",
      "ep: 3, loss: 2.3011, time 10.7 sec\n",
      "ep: 4, loss: 2.3010, time 10.7 sec\n",
      "ep: 5, loss: 2.3010, time 10.9 sec\n",
      "ep: 6, loss: 2.3010, time 11.1 sec\n",
      "ep: 7, loss: 2.3010, time 11.0 sec\n",
      "ep: 8, loss: 2.3010, time 11.0 sec\n",
      "ep: 9, loss: 2.3010, time 11.1 sec\n",
      "ep: 10, loss: 2.3010, time 11.1 sec\n",
      "ep: 11, loss: 2.3010, time 11.1 sec\n",
      "ep: 12, loss: 2.3010, time 11.1 sec\n",
      "ep: 13, loss: 2.3010, time 11.1 sec\n",
      "ep: 14, loss: 2.3010, time 11.0 sec\n",
      "ep: 15, loss: 2.3010, time 11.2 sec\n",
      "ep: 16, loss: 2.3010, time 11.1 sec\n",
      "ep: 17, loss: 2.3010, time 11.1 sec\n",
      "ep: 18, loss: 2.3010, time 11.1 sec\n",
      "ep: 19, loss: 2.3010, time 11.1 sec\n"
     ]
    }
   ],
   "source": [
    "# Обучение\n",
    "optim_lstm = torch.optim.Adam(model_lstm.parameters(), lr = 0.01)\n",
    "model_train(model = model_lstm, num_epochs = 20, optimizer = optim_lstm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c567dae-9d29-42b5-a2d4-9a67d788091b",
   "metadata": {},
   "source": [
    "##### 2.3. GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6d39926d-2c95-4bac-a328-d11a2017d33d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Класс для сети\n",
    "class GRU(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(len(CHAR_TO_INDEX), 30)\n",
    "        self.hidden = nn.GRU(input_size = 30, hidden_size = 128, batch_first = True)\n",
    "        self.out = nn.Linear(128, len(CHAR_TO_INDEX))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        x, s = self.hidden(x)\n",
    "        y = self.out(x)\n",
    "        return y\n",
    "\n",
    "model_gru = GRU()\n",
    "model_gru = model_gru.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d3b8c856-3c80-45c1-9aa5-ddb2fba7b419",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep: 0, loss: 0.0148, time 5.5 sec\n",
      "ep: 1, loss: 0.0000, time 5.2 sec\n",
      "ep: 2, loss: 0.0000, time 5.3 sec\n",
      "ep: 3, loss: 0.0000, time 5.3 sec\n",
      "ep: 4, loss: 0.0000, time 5.3 sec\n",
      "ep: 5, loss: 0.0000, time 5.5 sec\n",
      "ep: 6, loss: 0.0000, time 5.4 sec\n",
      "ep: 7, loss: 0.0000, time 5.3 sec\n",
      "ep: 8, loss: 0.0000, time 5.3 sec\n",
      "ep: 9, loss: 0.0000, time 5.3 sec\n",
      "ep: 10, loss: 0.0000, time 5.3 sec\n",
      "ep: 11, loss: 0.0110, time 5.4 sec\n",
      "ep: 12, loss: 0.0000, time 5.4 sec\n",
      "ep: 13, loss: 0.0000, time 5.4 sec\n",
      "ep: 14, loss: 0.0000, time 5.4 sec\n",
      "ep: 15, loss: 0.0000, time 5.4 sec\n",
      "ep: 16, loss: 0.0000, time 5.5 sec\n",
      "ep: 17, loss: 0.0000, time 5.4 sec\n",
      "ep: 18, loss: 0.0000, time 5.3 sec\n",
      "ep: 19, loss: 0.0000, time 5.5 sec\n"
     ]
    }
   ],
   "source": [
    "# Обучение\n",
    "optim_gru = torch.optim.Adam(model_gru.parameters(), lr = 0.01)\n",
    "model_train(model = model_gru, num_epochs = 20, optimizer = optim_gru)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13373ae9-218e-43ed-bfd9-eb2ad2894321",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### 3. Проверка работы модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "17b9a3de-24d2-453a-b426-a0f64590790d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50000/50000 [00:02<00:00, 20519.39it/s]\n"
     ]
    }
   ],
   "source": [
    "# Данные для проверки\n",
    "test = []\n",
    "for i in tqdm(range(5*10**4)):\n",
    "    number = ''\n",
    "    while True:\n",
    "        number += str(random.randint(0,9))\n",
    "        if len(number) == 50:\n",
    "            test.append(number)\n",
    "            break\n",
    "\n",
    "test_new = [(generate_seq(i)) for i in test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "aecce4bc-afd9-4e0c-9389-538f3b3541ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Словарь, где ключ - исходная последовательность, значение - преобразованная\n",
    "test_dict = dict(zip(test, test_new))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9d9b7b61-61dc-426d-a9d6-468b87877ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция для предсказаний и расчета точности\n",
    "INDEX_TO_CHAR = [w for w in '0123456789']\n",
    "def model_test(test, model, name):\n",
    "    accuracy = 0\n",
    "    for seq, seq_new in tqdm(test_dict.items()):\n",
    "        seq = list(seq)\n",
    "        seq = [CHAR_TO_INDEX.get(s, 0) for s in seq]\n",
    "        answers = model.to('cpu').forward(torch.tensor(seq))\n",
    "        probas, indices = answers.topk(1)\n",
    "        pred = ''.join([INDEX_TO_CHAR[ind.item()] for ind in indices.flatten()])\n",
    "        if pred == seq_new: \n",
    "            accuracy += 1\n",
    "        \n",
    "    print(f'Model: {name}, accuracy: {(accuracy/len(test) * 100):.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b43730ac-a880-4c75-9455-e52cfe8051c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50000/50000 [03:22<00:00, 246.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: RNN, accuracy: 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Тест RNN\n",
    "model_test(test = test_dict, model = model_rnn, name = 'RNN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "76dc5656-2f8f-4147-94ea-cc71c161cb6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50000/50000 [01:27<00:00, 573.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: LSTM, accuracy: 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Тест LSTM\n",
    "model_test(test = test_dict, model = model_lstm, name = 'LSTM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6dc80932-7f5f-43d2-8854-b389d30ca2fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50000/50000 [04:47<00:00, 173.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: GRU, accuracy: 100.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Тест GRU\n",
    "model_test(test = test_dict, model = model_gru, name = 'GRU')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63e2b675-8c62-4824-b40e-719a26ee7b8e",
   "metadata": {},
   "source": [
    "### Задание 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69fcc181-7325-4137-aae1-3328cc9b5209",
   "metadata": {},
   "source": [
    "#### 1. Загрузка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2ae629ca-5bfd-450c-8a91-1cfe25d06dac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length: 600893\n"
     ]
    }
   ],
   "source": [
    "# Загрузка файла, удаление пробелов, оставление только буквенных символов\n",
    "import re\n",
    "with open(r\"D:\\НЕТОЛОГИЯ\\Deep ML\\файлы\\nietzsche.txt\", encoding = 'utf-8') as f:\n",
    "    text = f.read().lower()\n",
    "print('length:', len(text))\n",
    "text = re.sub('[^a-z ]', ' ', text)\n",
    "text = re.sub('\\s+', ' ', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c997b2af-5a35-4024-b3bd-c9c4e1a6a5aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Словарь для символов\n",
    "INDEX_TO_CHAR2 = sorted(list(set(text)))\n",
    "CHAR_TO_INDEX2 = {c: i for i, c in enumerate(INDEX_TO_CHAR2)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f7b757c0-83e4-42c6-b953-d5b98abe1de1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num sents: 193075\n"
     ]
    }
   ],
   "source": [
    "# Разделение строк\n",
    "max_len2 = 40\n",
    "step = 3\n",
    "SENTENCES = []\n",
    "NEXT_CHARS = []\n",
    "for i in range(0, len(text) - max_len2, step):\n",
    "    SENTENCES.append(text[i: i + max_len2])\n",
    "    NEXT_CHARS.append(text[i + max_len2])\n",
    "print('Num sents:', len(SENTENCES))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e1bd519f-a2cb-4bc1-83ed-6f667264d3e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "193075it [01:03, 3050.51it/s]\n"
     ]
    }
   ],
   "source": [
    "#Векторизация\n",
    "X_text = torch.zeros((len(SENTENCES), max_len2), dtype=int)\n",
    "Y_text = torch.zeros((len(SENTENCES)), dtype=int)\n",
    "\n",
    "for i, sentence in tqdm(enumerate(SENTENCES)):\n",
    "    for t, char in enumerate(sentence):\n",
    "        X_text[i, t] = CHAR_TO_INDEX2[char]\n",
    "    Y_text[i] = CHAR_TO_INDEX2[NEXT_CHARS[i]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff98863e-a381-4497-b889-6b85a9fb3c94",
   "metadata": {},
   "source": [
    "#### 2. Обучение LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ed80efd6-e933-4a2c-b371-848f6c380170",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size2 = 512\n",
    "dataset = torch.utils.data.TensorDataset(X_text, Y_text)\n",
    "data = torch.utils.data.DataLoader(dataset, batch_size2, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "df5e8cb4-a661-45b7-9b7c-42ecb716ce88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Класс для сети\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self, rnnClass, dictionary_size, embedding_size, num_hiddens, num_classes):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.num_hiddens = num_hiddens\n",
    "        self.embedding = nn.Embedding(dictionary_size, embedding_size)\n",
    "        self.hidden = rnnClass(embedding_size, num_hiddens, batch_first=True)\n",
    "        self.output = nn.Linear(num_hiddens, num_classes)\n",
    "        \n",
    "    def forward(self, X):\n",
    "        out = self.embedding(X)\n",
    "        _, state = self.hidden(out)\n",
    "        predictions = self.output(state[0].squeeze())\n",
    "        return predictions\n",
    "\n",
    "model_lstm2 = NeuralNetwork(nn.LSTM, len(CHAR_TO_INDEX2), 64, 128, len(CHAR_TO_INDEX2))\n",
    "model_lstm2 = model_lstm2.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "00ee8a8f-bf65-4a44-938f-eed5aaf63076",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep: 5, loss: 1.2923, time 3.6 sec\n",
      "ep: 10, loss: 1.2929, time 3.7 sec\n",
      "ep: 15, loss: 1.3078, time 3.8 sec\n",
      "ep: 20, loss: 1.3659, time 3.8 sec\n",
      "ep: 25, loss: 1.3599, time 3.9 sec\n",
      "ep: 30, loss: 1.3727, time 3.9 sec\n",
      "ep: 35, loss: 1.4824, time 4.0 sec\n",
      "ep: 40, loss: 1.4287, time 4.1 sec\n",
      "ep: 45, loss: 1.5940, time 3.9 sec\n",
      "ep: 50, loss: 1.4370, time 3.9 sec\n"
     ]
    }
   ],
   "source": [
    "# Обучение модели\n",
    "loss = nn.CrossEntropyLoss()\n",
    "optim_lstm2 = torch.optim.Adam(model_lstm2.parameters(), lr = 0.01)\n",
    "\n",
    "for epoch in range(1, 51):\n",
    "    start = time.time()\n",
    "    train_loss = 0\n",
    "    train_passed = 0\n",
    "\n",
    "    model_lstm2.train()\n",
    "    for X_b, y_b in data:\n",
    "        X_b, y_b = X_b.to(device), y_b.to(device)\n",
    "        optim_lstm2.zero_grad()\n",
    "        answers = model_lstm2(X_b)\n",
    "        l = loss(answers, y_b)\n",
    "        train_loss += l.item()\n",
    "\n",
    "        l.backward()\n",
    "        optim_lstm2.step()\n",
    "        train_passed += 1\n",
    "\n",
    "    if epoch % 5 == 0:\n",
    "        print(f'ep: {epoch}, loss: {train_loss/train_passed:.4f}, time {time.time() - start:.1f} sec')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05a615b8-b7b2-4de8-983b-e94ecdc9a456",
   "metadata": {},
   "source": [
    "#### 3. Проверкак качества модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "697528e4-a623-4d36-8f26-0b1121c2e059",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Проверим, совападют ли сгенерерованные моделью продолжения последовательнотсей с таковыми из текста\n",
    "def sample(preds):\n",
    "    softmaxed = torch.softmax(preds, 0)\n",
    "    probas = torch.distributions.multinomial.Multinomial(1, softmaxed).sample()\n",
    "    return probas.argmax()\n",
    "\n",
    "def generate_test():\n",
    "    start_index = random.randint(0, len(text) - max_len2 - 1)\n",
    "\n",
    "    generated = ''\n",
    "    sentence = text[start_index: start_index + max_len2]\n",
    "    sentence_full = text[start_index: start_index + max_len2*2]\n",
    "    generated += sentence\n",
    "\n",
    "    for i in range(max_len2):\n",
    "        x_pred = torch.zeros((1, max_len2), dtype=int)\n",
    "        for t, char in enumerate(generated[-max_len2:]):\n",
    "            x_pred[0, t] = CHAR_TO_INDEX2[char]\n",
    "        \n",
    "        preds = model_lstm2(x_pred.to(device)).cpu()\n",
    "        next_char = INDEX_TO_CHAR2[sample(preds)]\n",
    "        generated = generated + next_char\n",
    "\n",
    "    print('1-ая половина предложения/Предсказание') \n",
    "    print(generated[:max_len2] + '/' + generated[max_len2:])\n",
    "    print('Предложение целиком') \n",
    "    print(sentence_full)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e8af31c7-edd5-4c6d-be2e-e4234fabfc34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1-ая половина предложения/Предсказание\n",
      "to jesuits and even ernest renan how ina/bly ind mean is escience of there is sym\n",
      "Предложение целиком\n",
      "to jesuits and even ernest renan how inaccessible to us northerners does the lan\n",
      "\n",
      "1-ая половина предложения/Предсказание\n",
      "will to deception or the generous deed o/f recolute and a verios the generall as \n",
      "Предложение целиком\n",
      "will to deception or the generous deed out of selfishness or the pure sun bright\n",
      "\n",
      "1-ая половина предложения/Предсказание\n",
      "ray something of the structure of his so/mathhing platence wither to instinct goe\n",
      "Предложение целиком\n",
      "ray something of the structure of his soul and wherein it sees its conditions of\n",
      "\n",
      "1-ая половина предложения/Предсказание\n",
      "owledge rear itself hitherto the will to/ like zepace and to here new the asseds \n",
      "Предложение целиком\n",
      "owledge rear itself hitherto the will to knowledge on the foundation of a far mo\n",
      "\n",
      "1-ая половина предложения/Предсказание\n",
      "ng ever more dangerous can we not upset /romanet for as evilie case internots tha\n",
      "Предложение целиком\n",
      "ng ever more dangerous can we not upset every standard and is good perhaps evil \n",
      "\n",
      "1-ая половина предложения/Предсказание\n",
      "the fundamental opposites that have brou/ge still in at kinive not of capsy derus\n",
      "Предложение целиком\n",
      "the fundamental opposites that have brought mankind to make a distinction betwee\n",
      "\n",
      "1-ая половина предложения/Предсказание\n",
      "is easier than to give it up occasionall/y faite with all imme fact extriene of a\n",
      "Предложение целиком\n",
      "is easier than to give it up occasionally as it is also easier wholly to renounc\n",
      "\n",
      "1-ая половина предложения/Предсказание\n",
      " know and consider it obligatory to know/ledge many is reasowher nown the firsf i\n",
      "Предложение целиком\n",
      " know and consider it obligatory to know that there is art in every good sentenc\n",
      "\n",
      "1-ая половина предложения/Предсказание\n",
      " confused that origin is the reverence d/oes a generage what is may not may and i\n",
      "Предложение целиком\n",
      " confused that origin is the reverence due to it increases from generation to ge\n",
      "\n",
      "1-ая половина предложения/Предсказание\n",
      "a real religious life alike for its favo/ur thing a subjeasion is the when and or\n",
      "Предложение целиком\n",
      "a real religious life alike for its favourite microscopic labour of self examina\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Сгенерируем 10 примеров и сравним предсказания модели с источником\n",
    "for i in range(10):\n",
    "    model_lstm2.eval()\n",
    "    generate_test()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
